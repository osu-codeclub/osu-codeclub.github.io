{
  "hash": "ecbfbd475c6f982568c59849b6cb3524",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using Copilot, `chattr`, and `ellmer`\"\nauthor:\n  - \"Jessica Cooperstone and Horacio Lopez-Nicora\"\ndate: \"2025-11-11\"\ncategories: [r-basics, tidyverse, github-copilot, chattr, ellmer, copilot, gen-ai, ggplot2]\ntitle-block-banner: false\nimage: img/chattr-ellmer-hex.png\nknitr:\n  opts_chunk:\n    out.width: \"85%\"\n    class-output: styled-output\n    fig.align: 'center'\n---\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n------------------------------------------------------------------------\n\n![`chattr` and `ellmer` hexes](img/chattr-ellmer-hex.png)\n\n# Introduction\n\nWe have spent the last handful of sessions using GitHub Copilot embedded in the RStudio IDE. Today we are going to try using:\n\n-   Microsoft Copilot in our browser\n-   The package [`chattr`](https://mlverse.github.io/chattr/) and [`ellmer`](https://ellmer.tidyverse.org/)\n\n## Loading data\n\nLet's use the same data as last week to play around. If you have it from last week, no need to download, but if you need to get it, you can download the file using the code below.\n\n::: callout-note\nRemember that files with by default be downloaded into your working directory.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# download the happiness data\ndownload.file(url = \"https://github.com/jcooperstone/dataviz-site/raw/refs/heads/master/2_04_wrangling/data/hapiscore_whr.csv\",\n              destfile = \"happiness.csv\")\n```\n:::\n\n\nAnd some data on life expectancy around the world from 1800 to predicted values from 2022-2100.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# download the life expectancy data\ndownload.file(url = \"https://github.com/jcooperstone/dataviz-site/raw/refs/heads/master/2_04_wrangling/data/life_expectancy.csv\",\n              destfile = \"life-expectancy.csv\")\n```\n:::\n\n\n# Get setup with Microsoft Copilot\n\nOpen a browser and navigate to [Microsoft Copilot](https://copilot.microsoft.com/). Log in with your OSU credentials and indicate you are using your Work account\n\n![Screenshot of selecting the Work Copilot experience](img/copilot-work.png)\n\nThis would be the way to use generative AI that is compliant with with OSU's data policies. You can learn more about this in OSU\"s administrative resource center page on [Copilot chat](https://admin.resources.osu.edu/microsoft-365/copilot-chat?check_logged_in=1).\n\n# Get setup with `chattr` and `ellmer`\n\nThe package `chattr` is a chat interface to using a large language model (LLM) with R. `chattr` lets you \"chat\" with your LLM via your script or in a Shiny Gadget. \n\nThe package `ellmer` helps make it easier to use LLMs with R.\n\n## Install\n\nFirst we will install both packages\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstall.packages(\"chattr\")\ninstall.packages(\"ellmer\")\n```\n:::\n\n\nThen we need to tell `chattr` which LLM we want to use. `ellmer` helps us do this, and at the time of writing this tutorial, it [supports lots of different models](https://ellmer.tidyverse.org/#providers):\n\n-   Anthropic’s Claude: `chat_anthropic()`\n-   AWS Bedrock: `chat_aws_bedrock()`\n-   Azure OpenAI: `chat_azure_openai()`\n-   Cloudflare: `chat_cloudflare()`\n-   Databricks: `chat_databricks()`\n-   DeepSeek: `chat_deepseek()`\n-   GitHub model marketplace: `chat_github()`.\n-   Google Gemini/Vertex AI: `chat_google_gemini()`, `chat_google_vertex().`\n-   Groq: `chat_groq()`\n-   Hugging Face: `chat_huggingface()`\n-   Mistral: `chat_mistral()`\n-   Ollama: `chat_ollama()`\n-   OpenAI: `chat_openai()`\n-   OpenRouter: `chat_openrouter()`\n-   perplexity.ai: `chat_perplexity()`\n-   Snowflake Cortex: `chat_snowflake()` and `c`hat_cortex_analyst()`\n-   VLLM: `chat_vllm()`\n\nYou can pick which one you'd like to use, for the rest of this session I am going to use Google Gemini since I have a google/gmail account (as assume many of you do too), and their free tier is generous. I am including instructions on how to get your Google Gemini API key, but if you want to use a different model you can search how to find that API key.\n\n:::callout-warning\nRemember, your API key is personal so do not share it in repositories or elsewhere. \n:::\n\n## Set up your API key\n\nTo get your Google API key, go to [https://aistudio.google.com/app/api-keys](https://aistudio.google.com/app/api-keys) and sign in with your Google credentials. \n\nI'm showing a screenshot below of what my Google AI studio looks like, yours may be slightly different and you want to create an API key if you don't have one. \n\n![Google AI studio for finding your API key](img/google-api.png)\n\nThen, you can click on the little double box to copy your API code. Your key code will be in your clipboard.\n\n![](img/copy-api.png)\n\nNow let's set our API key. We can do that in R like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# for Gemini\nSys.setenv(GOOGLE_API_KEY = \"YOUR_GOOGLE_API_KEY\")\n```\n:::\n\n\nAgain - if you have this in your scripts be sure then not to share them with anyone.\n\n:::callout-note\nThere is a more elegant way to do this by setting up our API key in our R environment `.Renviron` file but I'm not going to set that up until we decide we like this :)\n:::\n\n## Use `chattr`\n\nNow we are set up to launch our chat. First we need to load our packages.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(chattr)\nlibrary(ellmer)\n```\n:::\n\n\nThen we will tell `chattr` which LLM we want to use, with `ellmer` helping us:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchattr_use(ellmer::chat_google_gemini())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nUsing model = \"gemini-2.5-flash\".\n\n\n── chattr \n\n• Provider: Google/Gemini\n\n• Model: gemini-2.5-flash\n\n• Label: gemini-2.5-flash (Google/Gemini)\n```\n\n\n:::\n:::\n\n\nLet's see how well that worked:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# check our settings\nchattr_defaults()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── chattr ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Defaults for: Default ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Prompt: \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Model \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Provider: Google/Gemini\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Model: gemini-2.5-flash\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Label: gemini-2.5-flash (Google/Gemini)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Context: \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nMax Data Files: 0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nMax Data Frames: 0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✖ Chat History\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✖ Document contents\n```\n\n\n:::\n:::\n\n\nNow we can launch our chat app.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchattr_app()\n```\n:::\n\n\n\n\n# Let's ideate together what guidance we want to provide our LLM for helping us with code.\n\n# Tasks to play around with\n\nLet's together work on writing prompts to get R to write to complete each tasks or that answer the following questions:\n\n1.  Get R to read in your happiness and life expectancy data\n\n2.  Understand what your data contains\n\n3.  Which is the country with the highest life expectancy in 2025?\n\n4.  Which country increased life expectancy the most from 2000 to 2025?\n\n5.  Create a plot that shows the line expectancy in the United States over the time period for which we have data\n\n6.  Create a plot that shows the relationship between life expectancy and happiness score in 2022.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}